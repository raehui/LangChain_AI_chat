{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d2p_a81yZna_"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install langchain_community\n",
        "!pip install langchain_opneai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "#이전의 방식은 소스코드를 내가 업로드 했을 떄, 다른 사람들이 내 키를 볼 수 있음\n",
        "#'이름'==userdata.get(이름),값=내 open_api_key\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY']=userdata.get('OPEN_AI_KEY')\n",
        "\n",
        "openai.api_key=os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "3z4HkD0bZ1h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#대화형 프롬프트의 양식을 지정\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "\n",
        "#모델의 결과값을 원하는 방식으로 파싱(형태 변형)\n",
        "from langchain.schema import BaseOutputParser"
      ],
      "metadata": {
        "id": "upzYAdadZ1c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_template=ChatPromptTemplate.from_messages([\n",
        "    #openai처럼 role-content의 순서로 튜플을 전달하여 요청\n",
        "    (\"system\",\"댓글에 대해 감정 분석을 수행할 것,주어진 user_input에 대해 긍정적이면 1 부정적이면 0,오로지 0과 1로만 답할 것 \"),\n",
        "    (\"human\",\"{input_text}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "Wc6V-FQlZ1Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BaseoutputParser를 상속하여 새로운 클랫인 ClassificationOutputParser를 정의\n",
        "#이 클래스는 결과에 대해, str형태의 1과 0을 각각 정수 1과 0으로 변환하는 역할을 함\n",
        "\n",
        "class ClassificationOutputParser(BaseOutputParser):\n",
        "  def parse(self, text:str):\n",
        "    if '1' in text:\n",
        "      return 1\n",
        "    return 0"
      ],
      "metadata": {
        "id": "D-PLmoPHZ1XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LangChain에서 OpenAI의 대화형 모델을 사용하여 대화를 생성\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "#langchain에서 openai랑 대화할 모델의 정의\n",
        "chat_model=ChatOpenAI()\n",
        "\n",
        "#chain을 통해서 양식 생성 -> 모델에 전달 -> 결과값 정리 까지를 한꺼번에 처리\n",
        "#처리하는 함수를 객체로 사용함\n",
        "#chain이라는 함수로 다시 생성\n",
        "chain=chat_prompt_template | chat_model  |ClassificationOutputParser()"
      ],
      "metadata": {
        "id": "PK5h1Wv3bKvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def langchain_llm(input_text):\n",
        "    output=chain.invoke({'input_text':input_text})\n",
        "    return output\n",
        "    #output 0과 1의 값을 가짐"
      ],
      "metadata": {
        "id": "AkTptt8fZ1UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_text(input_text):\n",
        "    output=langchain_llm(input_text)\n",
        "    return output\n",
        "    #output=input_text 데이터를 lln 모델에 돌린값\n",
        "    #두 겹으로 함수를"
      ],
      "metadata": {
        "id": "ywatlrdRZ1Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###분석에 사용할 데이터 로드"
      ],
      "metadata": {
        "id": "tDasdxFMeJZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/tykimos/tykimos.github.io/master/warehouse/dataset/tarr_train.txt\",\n",
        "    filename=\"tarr_train.txt\",\n",
        ")"
      ],
      "metadata": {
        "id": "iBxY7OPHadPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#delimiter 어떤 걸로 분류되어 있는가?\n",
        "df=pd.read_csv(\"tarr_train.txt\",delimiter='\\t')"
      ],
      "metadata": {
        "id": "uf0gCYNzevVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "vdyBUm08adK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_labels=[]\n",
        "predicted_labels=[]\n",
        "\n",
        "total=len(df)\n",
        "\n",
        "for index,row in df.iterrows():\n",
        "    comment=row['comment']\n",
        "    actual_label=row['label']\n",
        "\n",
        "    #llm의 질의 응답을 받아옴\n",
        "    predicted_label=classify_text(comment)\n",
        "\n",
        "    actual_labels.append(actual_label)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "    print(f\"[{index+1}/{total}]\") #전체에서 몇 번째 실행?\n",
        "    print('comment',comment)  #댓글 내용\n",
        "    print('actual',actual_label) #실제 라벨\n",
        "    print('predict',predicted_label) #llm이 나눈 라벨\n",
        "\n",
        "    if index>10:\n",
        "        break"
      ],
      "metadata": {
        "id": "9gbglmLbdx8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 댓글에 대한 답변 생성"
      ],
      "metadata": {
        "id": "VXdM9garhLn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt_reply=ChatPromptTemplate.from_messages([\n",
        "    ('system',\"너는 친절한 20대 사장님이야. 긍정적인 댓글에는 감사함을 구체적으로 표현하고 부정적인 댓글에는 미안함을 표현하면서 개선사항을 함께 말해줘.대신 충청도 사투리를 사용해줘\"),\n",
        "    ('human','{input_text}')\n",
        "])\n"
      ],
      "metadata": {
        "id": "R0IJ8PPpdyTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "#답변 맥락 정의->모델에 넣기->결과만 나오게끔\n",
        "chain=chat_prompt_reply | chat_model | StrOutputParser()\n",
        "\n",
        "#인풋 데이터에 대한 답변을 생성하는 함수 생성\n",
        "def generate_reply(input_text):\n",
        "    output=langchain_llm(input_text)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ETtWtzXddyh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index,row in df.iterrows():\n",
        "    comment=row['comment']\n",
        "\n",
        "    #함수를 이용해서 댓글에 대한 답변 생성\n",
        "    reply=generate_reply(comment)\n",
        "\n",
        "    print(f\"[{index+1}/{total}]\")\n",
        "    print('comment',comment)\n",
        "    print(\"reply : \", reply)\n",
        "    print(\"---------------\")\n",
        "\n",
        "    if index > 3:\n",
        "        break"
      ],
      "metadata": {
        "id": "sSSh1NFreOQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-iBdxjBeOLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z244BpNofF3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IZ0WnJbVfF0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CokljKAPfFvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qkgT5ZkJiabf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0co13bWEiaVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q19v0ImmiaQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LryN3cShj1yM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}